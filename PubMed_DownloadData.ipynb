{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os, csv, gzip, glob\n",
    "from ftplib import FTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set Working Directory \n",
    "current_dir = \"YourWorkingDirectory\"\n",
    "raw_dir = os.path.join(current_dir, \"RawData\")\n",
    "\n",
    "# Create Raw Data Directory\n",
    "if not os.path.exists(raw_dir):\n",
    "    os.makedirs(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open connection with Pubmed and Download files from Medline Baseline\n",
    "# Data accessed in December 2017\n",
    "ftp = FTP(\"ftp.ncbi.nlm.nih.gov\")\n",
    "ftp.login()\n",
    "ftp.cwd(\"pubmed\")\n",
    "ftp.cwd(\"baseline\")\n",
    "file_names = ftp.nlst() \n",
    "\n",
    "# File #533 (hardcoded) is the first file with publication date in 2005\n",
    "# Note: At the time of data access, there are approximately ~400 files to download\n",
    "good_files = [file for file in file_names if (file.endswith(\".gz\") and int(file[9:13]) >= 533)]\n",
    "for file in good_files:\n",
    "    print(\"Writing: \" + file) \n",
    "    ftp.retrbinary(\"RETR \" + file, open(os.path.join(raw_dir, file), \"wb\").write)\n",
    "ftp.close() # close ftp connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns node text if there is text, else returns empty string\n",
    "def none_text(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    return node.text    \n",
    "\n",
    "# Extracts author first name (fname), last name (lname), and affiliation\n",
    "def extract_author_info(obj):\n",
    "    return({\n",
    "            \"fname\"      : none_text(obj.find(\"ForeName\")), \n",
    "            \"lname\"      : none_text(obj.find(\"LastName\")),\n",
    "            \"affiliation\": none_text(obj.find(\"AffiliationInfo/Affiliation\")), \n",
    "    })\n",
    "\n",
    "# Extracts and Writes journal name, publication year, article title, \n",
    "# first author's first and last name, last author's first and last name,\n",
    "# first author's affiliation, article type, middle authors, and if there is an abtract\n",
    "def write_journal_csv(csvwriter, node):\n",
    "    journal        = none_text(node.find(\"Article/Journal/Title\")) \n",
    "    year           = none_text(node.find(\"Article/Journal/JournalIssue/PubDate/Year\")) \n",
    "    title          = none_text(node.find(\"Article/ArticleTitle\"))\n",
    "    article_type   = none_text(node.find(\"Article/PublicationTypeList/PublicationType\"))\n",
    "    abstract       = node.find(\"Article/Abstract\") is not None\n",
    "    \n",
    "    author_list    = node.find(\"Article/AuthorList\") # author list\n",
    "    if author_list is not None:\n",
    "        authors        = author_list.findall(\"Author\") # authors\n",
    "        author_info    = [extract_author_info(author) for author in authors] # author information\n",
    "\n",
    "        fname_first    = author_info[0].get(\"fname\")\n",
    "        lname_first    = author_info[0].get(\"lname\")\n",
    "        affiliation    = author_info[0].get(\"affiliation\")\n",
    "\n",
    "        fname_last     = \"\"\n",
    "        lname_last     = \"\"\n",
    "        middle_authors = []\n",
    "        if len(author_info) > 1:\n",
    "            fname_last     = author_info[-1].get(\"fname\")\n",
    "            lname_last     = author_info[-1].get(\"lname\")\n",
    "            middle_authors = [author.get(\"fname\") for author in author_info[1:-1]]\n",
    "\n",
    "        csvwriter.writerow([journal, year, title, fname_first, lname_first, fname_last, \n",
    "                         lname_last, affiliation, article_type, middle_authors, abstract])\n",
    "\n",
    "# Given an XML file, will read the entire file to a CSV \n",
    "def process_xml_file(file):\n",
    "    output = open(file + \".csv\", \"w\")\n",
    "    csvwriter = csv.writer(output) \n",
    "    csvwriter.writerow([\"journal\", \"year\", \"title\", \"fname_first\", \"fname_last\", \n",
    "                         \"lname_first\", \"lname_last\", \"affiliation\", \"article_type\", \n",
    "                         \"middle_authors\", \"abstract\"])\n",
    "\n",
    "    tree = ET.parse(gzip.open(file))\n",
    "    root = tree.getroot()\n",
    "    nodes = root.findall(\"PubmedArticle/MedlineCitation\")\n",
    "    for node in nodes:\n",
    "        write_journal_csv(csvwriter, node)\n",
    "        \n",
    "    print(\"Done: \" + file + \".csv\")\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Locate all XML files downloaded from PubMed and Write to CSVs\n",
    "file_names = glob.glob(os.path.join(raw_dir, \"*.xml.gz\"))\n",
    "for file in file_names:\n",
    "    process_xml_file(file)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
